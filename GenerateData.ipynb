{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8cbaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100 features...\n",
      "Outlier Perc 0.1672\n",
      "Processing 500 features...\n",
      "Outlier Perc 0.1564\n",
      "Processing 1000 features...\n",
      "Outlier Perc 0.1526\n",
      "Processing 2000 features...\n",
      "Outlier Perc 0.1484\n",
      "Processing 5000 features...\n",
      "Outlier Perc 0.1496\n",
      "Data generation and storage completed.\n"
     ]
    }
   ],
   "source": [
    "from pyod.utils.data import generate_data_clusters\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "\n",
    "# Define the number of samples and feature dimensions\n",
    "n_samples = 5000\n",
    "n_features = [100, 500, 1000, 2000, 5000]\n",
    "n_train = int(n_samples * 0.6)  # 60% of samples for training\n",
    "n_test = int(n_samples * 0.4)  # 40% of samples for testing\n",
    "\n",
    "def generate_groups(n_feature):\n",
    "    groups = []\n",
    "\n",
    "    low = 6  # Lower limit of feature range\n",
    "    high = 20  # Upper limit of feature range\n",
    "\n",
    "    while n_feature > 0:\n",
    "        k = np.random.randint(low, high)\n",
    "        k = min(k, n_feature)\n",
    "        groups.append(k)\n",
    "        n_feature -= k\n",
    "\n",
    "    return groups\n",
    "\n",
    "# Random seed for shuffling features\n",
    "random_seed = 42  # You can choose any seed value\n",
    "\n",
    "# Generate and store data for different feature dimensions\n",
    "for n_feature in n_features:\n",
    "    print(f\"Processing {n_feature} features...\")\n",
    "\n",
    "    # Initialize training and test data sets\n",
    "    X_train = np.zeros((n_train, n_feature))\n",
    "    X_test = np.zeros((n_test, n_feature))\n",
    "    y_train = np.zeros((n_train, 1))\n",
    "    y_test = np.zeros((n_test, 1))\n",
    "\n",
    "    # Generate feature combinations\n",
    "    groups = generate_groups(n_feature)\n",
    "\n",
    "    # Initialize label matrices\n",
    "    y_train_label = np.zeros((n_train, len(groups)))\n",
    "    y_test_label = np.zeros((n_test, len(groups)))\n",
    "\n",
    "    i = 0\n",
    "    k = 0\n",
    "\n",
    "    for dimension in groups:\n",
    "#         print(dimension)\n",
    "\n",
    "        # Generate clustered data\n",
    "\n",
    "        a, b, c, d = generate_data_clusters(n_train, n_test, 2, dimension, contamination=0.18/len(groups))\n",
    "\n",
    "        # Fill feature data\n",
    "        X_train[:, i:i + dimension] = a\n",
    "        X_test[:, i:i + dimension] = b\n",
    "\n",
    "        # Update labels\n",
    "        \n",
    "        # label\n",
    "        y_train = y_train + c.reshape(n_train, 1)\n",
    "        y_test = y_test + d.reshape(n_test, 1)\n",
    "\n",
    "        #label for each group\n",
    "        y_train_label[:, k] = y_train.reshape(n_train,)\n",
    "        y_test_label[:, k] = y_test.reshape(n_test,)\n",
    "\n",
    "        i = i + dimension\n",
    "        k = k + 1\n",
    "\n",
    "    # Shuffle features using the same random seed\n",
    "    np.random.seed(random_seed)\n",
    "    permutation = np.random.permutation(n_feature)\n",
    "    X_train = X_train[:, permutation]\n",
    "    X_test = X_test[:, permutation]\n",
    "\n",
    "    # Convert labels to binary (1 if non-zero, 0 otherwise)\n",
    "    y_train = (y_train != 0) * 1\n",
    "    y_test = (y_test != 0) * 1\n",
    "    \n",
    "    print('Outlier Perc',(np.sum(y_train)+np.sum(y_test))/n_samples)\n",
    "    # Store data\n",
    "    Traindata = (X_train, y_train, y_train_label)\n",
    "    Testdata = (X_test, y_test, y_test_label)\n",
    "\n",
    "    joblibfile = f'Train{n_feature}_6_20.dat'\n",
    "    dump(Traindata, joblibfile)\n",
    "\n",
    "    joblibfile = f'Test{n_feature}_6_20.dat'\n",
    "    dump(Testdata, joblibfile)\n",
    "\n",
    "print(\"Data generation and storage completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c7ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
